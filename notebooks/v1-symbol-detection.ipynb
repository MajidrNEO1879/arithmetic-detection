{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb8095",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "from sympy import *\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    " \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf41ac87",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/MajidrNEO1879/arithmetic-detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f31089",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CocoDetectionDataset(Dataset):\n",
    "    # Init function: loads annotation file and prepares list of image IDs\n",
    "    def __init__(self, image_dir, annotation_path, transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.coco = COCO(annotation_path)\n",
    "        self.image_ids = list(self.coco.imgs.keys())\n",
    "        self.transforms = transforms\n",
    " \n",
    "    # Returns total number of images\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    " \n",
    "    # Fetches a single image and its annotations\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(self.image_dir, image_info['file_name'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    " \n",
    "        # Load all annotations for this image\n",
    "        annotation_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "        annotations = self.coco.loadAnns(annotation_ids)\n",
    " \n",
    "        # Extract bounding boxes and labels from annotations\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in annotations:\n",
    "            xmin, ymin, width, height = obj['bbox']\n",
    "            xmax = xmin + width\n",
    "            ymax = ymin + height\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(obj['category_id'])\n",
    " \n",
    "        # Convert annotations to PyTorch tensors\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        area = torch.as_tensor([obj['area'] for obj in annotations],    dtype=torch.float32)\n",
    "        iscrowd = torch.as_tensor([obj.get('iscrowd', 0) for obj in annotations], dtype=torch.int64)\n",
    " \n",
    "        # Package everything into a target dictionary\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd\n",
    "        }\n",
    " \n",
    "        # Apply transforms if any were passed\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    " \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0079f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    return ToTensor()\n",
    " \n",
    "# Load training dataset\n",
    "train_dataset = CocoDetectionDataset(\n",
    "    image_dir=\"/content/arithmetic-detection/train\", \n",
    "    annotation_path=\"/content/arithmetic-detection/train/_annotations.coco.json\",\n",
    "    transforms=get_transform()\n",
    ")\n",
    " \n",
    "# Load validation dataset\n",
    "val_dataset = CocoDetectionDataset(\n",
    "    image_dir=\"/content/arithmetic-detection/valid\",\n",
    "    annotation_path=\"/content/arithmetic-detection/valid/_annotations.coco.json\",\n",
    "    transforms=get_transform()\n",
    ")\n",
    "# Load dataset with DataLoaders, you can change batch_size \n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f25f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "category_ids = train_dataset.coco.getCatIds()\n",
    "num_classes = len(category_ids)\n",
    "categories = train_dataset.coco.loadCats(category_ids)\n",
    "class_names = [cat['name'] for cat in categories]\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222e446",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))\n",
    " \n",
    "# loop through one batch and draw bounding boxes and labels\n",
    "for i in range(len(images)):\n",
    "    # CxHxW --> HxWxC\n",
    "    image = images[i].permute(1, 2, 0).numpy()   \n",
    "    # Rescale\n",
    "    image = (image * 255).astype(np.uint8)   \n",
    "    # Convert RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "     \n",
    "    # get bounding box coordinates and labels\n",
    "    boxes = targets[i]['boxes']\n",
    "    labels = targets[i]['labels']\n",
    " \n",
    "    for box, label in zip(boxes, labels):\n",
    "        x1, y1, x2, y2 = map(int, box.tolist())\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"Class {label.item()}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    " \n",
    "    # Show image with bboxes using matplotlib\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Sample {i + 1}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
